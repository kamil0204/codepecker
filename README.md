# Codebase Analyzer - Data Ingestion Tool

A modular data ingestion tool that uses LLM to identify entry points, tree-sitter to parse code, and graph databases to store static call stack analysis.

## Features

- üß† **LLM Integration**: Uses GPT-4o to identify entry points from project structure
- üå≥ **Tree-sitter Parsing**: Extracts classes, methods, and visibility from C# files
- üìä **Graph Database**: Stores hierarchical call stack data with switchable backends
- üèóÔ∏è **Modular Architecture**: Factory pattern for easy database switching
- üìÅ **Directory Scanning**: Respects `.gitignore` files and generates clean tree output

## Project Structure

```
‚îú‚îÄ‚îÄ ingestion.py               # Data ingestion entry point
‚îú‚îÄ‚îÄ server.py                  # Web server and API
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îú‚îÄ‚îÄ web/                      # Web interface
‚îÇ   ‚îú‚îÄ‚îÄ templates/            # HTML templates
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html        # Main dashboard
‚îÇ   ‚îî‚îÄ‚îÄ static/               # Static assets (CSS, JS)
‚îú‚îÄ‚îÄ src/                      # Source code modules
‚îÇ   ‚îú‚îÄ‚îÄ core/                 # Core configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Environment-based settings
‚îÇ   ‚îú‚îÄ‚îÄ database/             # Graph database implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_db_interface.py      # Abstract interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sqlite_graph_db.py         # SQLite implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_db_factory.py        # Factory pattern
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ future_graph_dbs.py        # Example implementations
‚îÇ   ‚îú‚îÄ‚îÄ llm/                  # LLM integration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_client.py     # OpenAI API client
‚îÇ   ‚îú‚îÄ‚îÄ parsers/              # Code parsing modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_parser.py    # Abstract parser interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ csharp_parser.py  # C# tree-sitter implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parser_manager.py # Multi-language coordinator
‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Utility functions
‚îÇ       ‚îî‚îÄ‚îÄ directory_scanner.py # Directory traversal
‚îú‚îÄ‚îÄ scripts/                  # Development and demo scripts
‚îÇ   ‚îú‚îÄ‚îÄ debug_parser.py       # Parser debugging
‚îÇ   ‚îú‚îÄ‚îÄ demo_db_switching.py  # Database switching demo
‚îÇ   ‚îî‚îÄ‚îÄ verify_db.py          # Database verification
‚îî‚îÄ‚îÄ docs/                     # Documentation
    ‚îú‚îÄ‚îÄ GRAPH_DB_README.md    # Database architecture guide
    ‚îî‚îÄ‚îÄ codebase_review_plan.md # Analysis planning
```

## Quick Start

## Quick Start

### üöÄ **One-Command Demo**
```bash
python demo.py
```
This will guide you through the complete workflow: data ingestion ‚Üí web server ‚Üí browser interface.

### üìã **Manual Setup**

1. **Install Dependencies**:
1. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Set Environment Variables**:
2. **Set Environment Variables**:
   Create a `.env` file with your database configuration:
   ```env
   NEO4J_URI=bolt://localhost:7687
   NEO4J_USERNAME=neo4j
   NEO4J_PASSWORD=your_password
   ```

3. **Configure Target Project** in `ingestion.py`:
   ```python
   project_path = "path/to/your/csharp/project"
   ```

4. **Run Analysis**:
   ```bash
   python ingestion.py
   ```

5. **Start Web Server**:
   ```bash
   python server.py
   ```

6. **Open Browser**: Navigate to `http://localhost:5000`

## Database Switching

The tool supports multiple graph database backends through a factory pattern:

```python
# Use Neo4j (default)
db = CallStackGraphDB(db_type="neo4j", uri="bolt://localhost:7687", 
                     username="neo4j", password="your_password")

# Use SQLite (alternative)
db = CallStackGraphDB(db_type="sqlite", db_path="my_graph.db")
```

## Output Format

The tool generates a hierarchical call stack showing:
- **Classes** with file paths and visibility
- **Methods** nested under their containing classes
- **Visibility modifiers** (Public, Private, Protected, Internal)

Example output:
```
CompanyController (Type:Class, Visibility:Public)
    |____> GetAllCompanyNameAsync (Type:Method, Visibility:Public)
    |____> GetCompaniesAsync (Type:Method, Visibility:Public)
```

## Web Server & API

After running the data ingestion, you can start a web server to explore the data:

```bash
python server.py
```

This starts a Flask web server at `http://localhost:5000` with:

### üåê **Web Interface**
- **Interactive Dashboard**: View all classes and their methods
- **Class Selection**: Click on any class to see its detailed graph
- **Statistics**: Overview of total classes, methods, and method calls
- **Responsive Design**: Works on desktop and mobile

### üì° **REST API Endpoints**
- `GET /api/health` - Health check and database status
- `GET /api/classes` - List all classes (entry points)
- `GET /api/class/<name>/graph` - Get detailed graph for a specific class
- `GET /api/graph/full` - Get complete graph data
- `GET /api/stats` - Database statistics

### üöÄ **Usage Workflow**
1. Run `python ingestion.py` to populate the database
2. Start `python server.py` to launch the web interface
3. Open `http://localhost:5000` in your browser
4. Explore your codebase interactively!

## Dependencies

- `pathspec` - For .gitignore file parsing
- `openai` - For LLM integration
- `httpx` - HTTP client with proxy support
- `requests` - For authentication requests
- `neo4j` - Neo4j graph database driver
- `python-dotenv` - Environment variable management
- `flask` - Web server framework
- `flask-cors` - Cross-origin resource sharing
